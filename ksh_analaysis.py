# -*- coding: utf-8 -*-
"""
Created on Tue Dec 10 13:34:40 2019

@author: msbak
"""

#import hdf5storage
import os  # 경로 관리
# library import
import pickle # python 변수를 외부저장장치에 저장, 불러올 수 있게 해줌
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime # 시관 관리 
import csv
import random
#import tensorflow as tf
#from tensorflow.keras import regularizers

from keras import regularizers
from keras.layers.core import Dropout
from keras import initializers
import keras
from keras.layers.core import Dense, Activation
from keras.layers.recurrent import LSTM
from keras.layers.wrappers import Bidirectional
from keras.optimizers import Adam

try:
    savepath = 'D:\\mscore\\syncbackup\\paindecoder\\save\\tensorData\\'; os.chdir(savepath)
except:
    try:
        savepath = 'C:\\Users\\skklab\\Google 드라이브\\save\\tensorData\\'; os.chdir(savepath);
    except:
        try:
            savepath = 'D:\\painDecorder\\save\\tensorData\\'; os.chdir(savepath);
        except:
            savepath = ''; # os.chdir(savepath);
print('savepath', savepath)



with open(savepath + 'msGroup_ksh.pickle', 'rb') as f:  # Python 3: open(..., 'wb')
    msGroup = pickle.load(f)
    print('msGroup_ksh.pickle load')
    
capsaicinGroup = msGroup['capsaicinGroup']
vehicleGroup = msGroup['vehicleGroup'] 
signalss = msGroup['signalss']
signalss_pc = msGroup['signalss_pc']
behavss = msGroup['behavss']
bg = msGroup['bg']

grouped_total_list = bg # 
bins = 10 # 최소 time frame 간격    
N = 14 

##
def smoothListGaussian(array1,window):  
     window = round(window)
     degree = (window+1)/2
     weight=np.array([1.0]*window)  
     weightGauss=[]  

     for i in range(window):  
         i=i-degree+1  
         frac=i/float(window)  
         gauss=1/(np.exp((4*(frac))**2))  
         weightGauss.append(gauss)  

     weight=np.array(weightGauss)*weight  
     smoothed=[0.0]*(array1.shape[0]-window)
     
     weight = weight / np.sum(weight) # nml

     for i in range(len(smoothed)):  
         smoothed[i]=sum(np.array(array1[i:i+window])*weight)/sum(weight)  

     return smoothed 

# downsampling
def downsampling(signalss, wanted_size):
    downratio = signalss[0][0].shape[0]/wanted_size
    signalss2 = []; [signalss2.append([]) for u in range(N)]
    for SE in range(N):
        [signalss2[SE].append([]) for u in range(3)]
        for se in range(3):
            signal = np.array(signalss[SE][se])
            
            downsignal = np.zeros(wanted_size)
            downsignal[:] = np.nan
            for frame in range(wanted_size):
                s = int(round(frame*downratio))
                e = int(round(frame*downratio+downratio))
                downsignal[frame] = np.mean(signal[s:e])
                
            signalss2[SE][se] = downsignal
    return np.array(signalss2)

##
behavss = np.array(msGroup['behavss'])
behavss2 = []; [behavss2.append([]) for u in range(N)]  
behavss3 = []; [behavss3.append([]) for u in range(N)]  
for SE in range(N):
    [behavss2[SE].append([]) for u in range(3)]
    [behavss3[SE].append([]) for u in range(3)]
    for se in range(3):
        behavss2[SE][se] = np.array(smoothListGaussian(behavss[SE][se],40))
        
signalss = np.array(msGroup['signalss'])
signalss2 = []; [signalss2.append([]) for u in range(N)]
for SE in range(N):
    [signalss2[SE].append([]) for u in range(3)]
    for se in range(3):
        signalss2[SE][se] = np.array(smoothListGaussian(signalss[SE][se],40))

wanted_size = np.min([behavss2[0][0].shape[0], signalss2[0][0].shape[0]])
signalss2 = downsampling(signalss2, wanted_size)
behavss2 = downsampling(behavss2, wanted_size)

## threshold binarization
for SE in range(N):
    for se in range(3):
        behavss2[SE][se] = behavss2[SE][se] > 240 # behav thr
        behavss3[SE][se] = behavss2[SE][se] # behav thr
        
# downsampling
ds = int(round(wanted_size/40)) # downsize
signalss2 = downsampling(signalss2, ds) # bg signal
signalss_pc = downsampling(behavss3, ds) # pc signal
behavss2 = downsampling(behavss2, ds) # pc signa
fn = 3 # main stream feature 몇개 넣을지
del signalss; del behavss
signalss = signalss2; behavss = behavss2

#plt.plot(behavss[1][1])

totaldataset = grouped_total_list
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
def array_recover(X_like):
    X_like_toarray = []; X_like = np.array(X_like)
    for input_dim in range(msunit *fn):
        tmp = np.zeros((X_like.shape[0],X_like[0,input_dim].shape[0]))
        for row in range(X_like.shape[0]):
            tmp[row,:] = X_like[row,input_dim]
    
        X_like_toarray.append(tmp)
        
        X_like_toarray[input_dim] =  \
        np.reshape(X_like_toarray[input_dim], (X_like_toarray[input_dim].shape[0],X_like_toarray[input_dim].shape[1],1))
    
    return X_like_toarray

# data 생성
SE = 70; se = 1; label = 1; roiNum=None; GAN=False; Mannual=False; mannual_signal=None; passframesave=np.array([])
def dataGeneration(SE, se, label, roiNum=None, bins=bins, GAN=False, \
                   mannual_signal=None, mannual_signal2=None, mannual_signal3=None, passframesave=np.array([])):    
    X = []; Y = []; Z = []

    if label == 0:
        label = [1, 0] # nonpain
    elif label == 1:
        label = [0, 1] # pain

    signal1 = np.mean(mannual_signal, axis=1) # BG signal
    signal2 = np.mean(mannual_signal2, axis=1) # movement
    signal3 = np.mean(mannual_signal3, axis=1) # PC signal
    
    #
#    signal1 = signal2
    
    lastsave = np.zeros(msunit, dtype=int)
#    lastsave2 = np.zeros(msunit, dtype=int) # 체크용
    
    binlist = list(range(0, full_sequence-np.min(sequenceSize), bins))

#    if passframesave.shape[0] != 0:
#        binlist = passframesave

    t4_save = []
    for frame in binlist:   
        X_tmp = []; [X_tmp.append([]) for k in range(msunit *fn)] 

        if True:
            signal1 = np.array(signal1)
            for unit in range(msunit):
                if frame <= full_sequence - sequenceSize[unit]:
                    X_tmp[unit] = (signal1[frame : frame + sequenceSize[unit]])
                    lastsave[unit] = frame
                    
                    if unit == 0:
                        t4_save.append(np.mean(signal1[frame : frame + sequenceSize[unit]]))
                    
                else:
                    X_tmp[unit] = (signal1[lastsave[unit] : lastsave[unit] + sequenceSize[unit]])
    #                print(frame, unit, lastsave[unit])
                    if unit == 0:
                        t4_save.append(np.mean(signal1[lastsave[unit] : lastsave[unit] + sequenceSize[unit]]))
        
        if True:
            signal2 = np.array(signal2)
            for unit in range(msunit):
                if frame <= full_sequence - sequenceSize[unit]:
                    X_tmp[unit+msunit] = (signal2[frame : frame + sequenceSize[unit]])
                    lastsave[unit] = frame
                    
                    if unit == 0:
                        t4_save.append(np.mean(signal2[frame : frame + sequenceSize[unit]]))
                    
                else:
                    X_tmp[unit+msunit] = (signal2[lastsave[unit] : lastsave[unit] + sequenceSize[unit]])
    #                print(frame, unit, lastsave[unit])
                    if unit == 0:
                        t4_save.append(np.mean(signal2[lastsave[unit] : lastsave[unit] + sequenceSize[unit]]))
                    
        if True:
            signal3 = np.array(signal3)
            for unit in range(msunit):
                if frame <= full_sequence - sequenceSize[unit]:
                    X_tmp[unit+msunit*2] = (signal2[frame : frame + sequenceSize[unit]])
                    lastsave[unit] = frame
                    
                    if unit == 0:
                        t4_save.append(np.mean(signal2[frame : frame + sequenceSize[unit]]))
                    
                else:
                    X_tmp[unit+msunit*2] = (signal2[lastsave[unit] : lastsave[unit] + sequenceSize[unit]])
    #                print(frame, unit, lastsave[unit])
                    if unit == 0:
                        t4_save.append(np.mean(signal2[lastsave[unit] : lastsave[unit] + sequenceSize[unit]]))
                
        X.append(X_tmp)
        Y.append(label)
        Z.append([SE,se])

    return X, Y, Z, t4_save

# 최소길이 찾기
mslength = np.zeros((N,5)); mslength[:] = np.nan
for SE in range(N):
    if SE in totaldataset:
        for se in range(3):
#            if [SE, se] in longlist:
            signal = np.array(signalss[SE][se])
            mslength[SE,se] = signal.shape[0]

full_sequence = int(np.nanmin(mslength))
print('full_sequence', full_sequence, 'frames')

#signalss_cut = preprocessing(endpoint=int(full_sequence))
# index msunit
msunit = 4 # input으로 들어갈 시계열 길이 및 갯수를 정함. full_sequence기준으로 1/n, 2/n ... n/n , n/n

sequenceSize = np.zeros(msunit) # 각 시계열 길이들을 array에 저장
for i in range(msunit):
    sequenceSize[i] = int(full_sequence/msunit*(i+1))
sequenceSize = sequenceSize.astype(np.int)

print('full_sequence', full_sequence)
print('sequenceSize', sequenceSize)

###############mnd
# hyperparameters #############
 
# learning intensity
epochs = 40 # epoch 종료를 결정할 최소 단위.
lr = 2e-4 # learning rate

n_hidden = int(8 * 6) # LSTM node 갯수, bidirection 이기 때문에 2배수로 들어감.
layer_1 = int(8 * 6) # fully conneted laye node 갯수 # 8

#duplicatedNum = 1
#mspainThr = 0.27
#acitivityThr = 0.4
# 1부터 2배수로 test 결과 8이 performance가 충분한 최소 단위임.

# regularization
l2_rate = 0.5 # regularization 상수
dropout_rate1 = 0.20 # dropout late
dropout_rate2 = 0.10 # 

#testsw = False  # test 하지 않고 model만 저장함. # cloud 사용량을 줄이기 위한 전략.. 
trainingsw = True # training 하려면 True 
statelist = ['exp'] # ['exp', 'con']  # random shuffled control 사용 유무
validation_sw = True # 시각화목적으로만 test set을 validset으로 배치함.
testsw2 = True
#if testsw2:
##    import os
#    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
#    os.environ['CUDA_VISIBLE_DEVICES'] = ''
#    import tensorflow as tf

# 집 컴퓨터, test 전용으로 수정
c1 = savepath == 'D:\\painDecorder\\save\\tensorData\\' or savepath == 'E:\\mscore\\syncbackup\\paindecoder\\save\\tensorData\\'
if False and c1:
    trainingsw = False
    testsw2 = True

acc_thr = 0.90 # 0.93 -> 0.94
batch_size = 2**8 # 5000
###############

# constant 
maxepoch = 100
n_in =  1 # number of features
n_out = 2 # number of class # 20191104: 3 class로 시도
classratio = 1 # class under sampling ratio

project_list = []
#project_list.append(['1212_ksh_w1_1', 500, None])
#project_list.append(['1212_ksh_w1_2', 600, None])
#project_list.append(['1212_ksh_w1_3', 700, None])
#project_list.append(['1212_ksh_w1_4', 800, None])
#project_list.append(['1212_ksh_w1_5', 100, None])
#project_list.append(['1212_ksh_w1_6', 200, None])
#project_list.append(['1212_ksh_w1_7', 300, None])
#project_list.append(['1212_ksh_w1_8', 400, None])

#project_list.append(['1216_ksh_signalonly_1', 100, None])
#project_list.append(['1216_ksh_signalonly_2', 500, None])
#project_list.append(['1216_ksh_signalonly_3', 600, None])

project_list.append(['1216_ksh_fix_1', 500, None])
project_list.append(['1216_ksh_fix_2', 600, None])
project_list.append(['1216_ksh_fix_3', 700, None])
project_list.append(['1216_ksh_fix_4', 800, None])
project_list.append(['1216_ksh_fix_5', 900, None])
project_list.append(['1216_ksh_fix_6', 100, None])
project_list.append(['1216_ksh_fix_7', 200, None])

bRNN_save = [];

q = project_list[0]
for q in project_list:
    settingID = q[0]; seed = q[1]; seed2 = int(seed+1)
    continueSW = q[2]
    
    print('settingID', settingID, 'seed', seed, 'continueSW', continueSW)

    # set the pathway2
    RESULT_SAVE_PATH = './result/'
    if not os.path.exists(RESULT_SAVE_PATH):
        os.mkdir(RESULT_SAVE_PATH)

    RESULT_SAVE_PATH = './result/' + settingID + '//'
    if not os.path.exists(RESULT_SAVE_PATH):
        os.mkdir(RESULT_SAVE_PATH)
    
    if not os.path.exists(RESULT_SAVE_PATH + 'exp/'):
        os.mkdir(RESULT_SAVE_PATH + 'exp/')
    
    if not os.path.exists(RESULT_SAVE_PATH + 'exp_raw/'):
        os.mkdir(RESULT_SAVE_PATH + 'exp_raw/')
    
    if not os.path.exists(RESULT_SAVE_PATH + 'control/'):
        os.mkdir(RESULT_SAVE_PATH + 'control/')
    
    if not os.path.exists(RESULT_SAVE_PATH + 'control_raw/'):
        os.mkdir(RESULT_SAVE_PATH + 'control_raw/')
    
    if not os.path.exists(RESULT_SAVE_PATH + 'model/'):
        os.mkdir(RESULT_SAVE_PATH + 'model/')
    
    if not os.path.exists(RESULT_SAVE_PATH + 'tmp/'):
        os.mkdir(RESULT_SAVE_PATH + 'tmp/')

    testset = []
    trainingset = list(totaldataset)
    for u in testset:
        try:
            trainingset.remove(u)
        except:
            pass
# In[]    
    # initiate
    def ms_sampling():
        sampleNum = []; [sampleNum.append([]) for u in range(n_out)]
        
        datasetX = []; datasetY = []; datasetZ = []
        for classnum in range(n_out):
            datasetX.append([]); datasetY.append([]); datasetZ.append([])
            
        # nonpain     
        msclass = 0 # nonpain
        X_tmp = []; Y_tmp = []; Z_tmp = []; T_tmp = []
        for SE in range(N):
            if SE in trainingset:
                for se in range(5):      
                    # pain Group에 들어갈 수 있는 모든 경우의 수 
                    c1 = SE in capsaicinGroup and se in [0]
                    c2 = SE in vehicleGroup and se in [0,1,2]
                    
                    if c1 or c2:# 
                        mssignal1 = signalss[SE][se]
                        mssignal2 = behavss[SE][se]
                        mssignal3 = signalss_pc[SE][se]
                        msbins = np.arange(0, mssignal1.shape[0]-full_sequence+1, bins)
                        
                        for u in msbins:
                            mannual_signal = mssignal1[u:u+full_sequence]
                            mannual_signal = np.reshape(mannual_signal, (mannual_signal.shape[0], 1))
                            
                            mannual_signal2 = mssignal2[u:u+full_sequence]
                            mannual_signal2 = np.reshape(mannual_signal2, (mannual_signal2.shape[0], 1))
                            
                            mannual_signal3 = mssignal3[u:u+full_sequence]
                            mannual_signal3 = np.reshape(mannual_signal3, (mannual_signal3.shape[0], 1))

                            X, Y, Z, t4_save = dataGeneration(SE, se, label=msclass, \
                                           mannual_signal=mannual_signal, mannual_signal2=mannual_signal2 \
                                           , mannual_signal3=mannual_signal3)
                  
                            X_tmp += X; Y_tmp += Y; Z_tmp += Z; T_tmp += t4_save 
                    
        datasetX[msclass] = X_tmp; datasetY[msclass] = Y_tmp; datasetZ[msclass] = Z_tmp
        
        sampleNum[msclass] = len(datasetX[msclass])
        print('nonpain_sampleNum', sampleNum[msclass])
        
        msclass = 1 # pain
        X_tmp = []; Y_tmp = []; Z_tmp = []
        for SE in range(N):
            if SE in trainingset:
                for se in range(5):      
                    # pain Group에 들어갈 수 있는 모든 경우의 수 
                    c1 = SE in capsaicinGroup and se in [1]
                    
                    if c1:# 
                        mssignal1 = signalss[SE][se]
                        mssignal2 = behavss[SE][se]
                        mssignal3 = signalss_pc[SE][se]
                        msbins = np.arange(0, mssignal1.shape[0]-full_sequence+1, bins)
                        
                        for u in msbins:
                            mannual_signal = mssignal1[u:u+full_sequence]
                            mannual_signal = np.reshape(mannual_signal, (mannual_signal.shape[0], 1))
                            
                            mannual_signal2 = mssignal2[u:u+full_sequence]
                            mannual_signal2 = np.reshape(mannual_signal2, (mannual_signal2.shape[0], 1))
                            
                            mannual_signal3 = mssignal3[u:u+full_sequence]
                            mannual_signal3 = np.reshape(mannual_signal3, (mannual_signal3.shape[0], 1))

                            X, Y, Z, t4_save = dataGeneration(SE, se, label=msclass, \
                                           mannual_signal=mannual_signal, mannual_signal2=mannual_signal2 \
                                           , mannual_signal3=mannual_signal3)
                  
                            X_tmp += X; Y_tmp += Y; Z_tmp += Z; T_tmp += t4_save 
                    
        datasetX[msclass] = np.array(X_tmp)
        datasetY[msclass] = np.array(Y_tmp)
        datasetZ[msclass] = np.array(Z_tmp)
        sampleNum[msclass] = len(datasetX[msclass]); print('pain_sampleNum', sampleNum[msclass])
            
        diff = sampleNum[0] - sampleNum[1]
        print('painsample #', diff, '부족, duplicate로 채움')
        msclass = 1
        
        for u in range(int(diff/sampleNum[1])):
            datasetX[msclass] = np.concatenate((np.array(datasetX[msclass]), np.array(X_tmp)), axis=0)
            datasetY[msclass] = np.concatenate((np.array(datasetY[msclass]), np.array(Y_tmp)), axis=0)
            datasetZ[msclass] = np.concatenate((np.array(datasetZ[msclass]), np.array(Z_tmp)), axis=0)
              
        remain = diff % sampleNum[1]    
              
        random.seed(seed)
        rix = random.sample(range(len(X_tmp)), remain)
                  
        datasetX[msclass] = np.concatenate((np.array(datasetX[msclass]), np.array(X_tmp)[rix]), axis=0)
        datasetY[msclass] = np.concatenate((np.array(datasetY[msclass]), np.array(Y_tmp)[rix]), axis=0)
        datasetZ[msclass] = np.concatenate((np.array(datasetZ[msclass]), np.array(Z_tmp)[rix]), axis=0)

        return datasetX, datasetY, datasetZ
    
    X_save2, Y_save2, Z_save2 = ms_sampling()
#    if continueSW != None:
#        X_save2, Y_save2, Z_save2, t4_save = ms_sampling_continue()
#    painindex_classs = np.concatenate((painindex_class0, painindex_class1), axis=0)
    #  datasetX = X_save; datasetY = Y_save; datasetZ = Z_save
    
    for i in range(n_out):
        print('class', str(i),'sampling 이후', np.array(X_save2[i]).shape[0])

    X = np.array(X_save2[0]); Y = np.array(Y_save2[0]); Z = np.array(Z_save2[0])
    for i in range(1,n_out):
        X = np.concatenate((X,X_save2[i]), axis = 0)
        Y = np.concatenate((Y,Y_save2[i]), axis = 0)
        Z = np.concatenate((Z,Z_save2[i]), axis = 0)

    X = array_recover(X)
    Y = np.array(Y); Y = np.reshape(Y, (Y.shape[0], n_out))
    indexer = np.array(Z)

    # control: label을 session만 유지하면서 무작위로 섞음
    Y_control = np.array(Y)
    for SE in range(N):
        for se in range(5):
            cbn = [SE, se]
            
            identical_ix = np.where(np.sum(indexer==cbn, axis=1)==2)[0]
            if identical_ix.shape[0] != 0:
                random.seed(None)  # control의 경우 seed 없음
                dice = random.choice([[1,0], [0,1]])
                Y_control[identical_ix] = dice
                
    # cross validation을 위해, training / test set split            
    # mouselist는 training set에 사용된 list임.
    # training set에 사용된 mouse의 마릿수 만큼 test set을 따로 만듦
    
    inputsize = np.zeros(msunit *fn, dtype=int) 
    for unit in range(msunit *fn):
        inputsize[unit] = X[unit].shape[1] # size 정보는 계속사용하므로, 따로 남겨놓는다.
        
    def keras_setup():
        #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras
        
        dt = datetime.now()
        idcode = dt.year * 10**4 + dt.month * 10**(4-2) + dt.day * 10**(4-4) + dt.hour * 10**(4-6)

        #init = initializers.glorot_normal(seed=None)

        init = initializers.he_uniform(seed=seed) # he initializer를 seed 없이 매번 random하게 사용 -> seed 줌
        
        input1 = []; [input1.append([]) for i in range(msunit *fn)] # 최초 input layer
        input2 = []; [input2.append([]) for i in range(msunit *fn)] # input1을 받아서 끝까지 이어지는 변수
        
        for unit in range(msunit *fn):
            input1[unit] = keras.layers.Input(shape=(inputsize[unit], n_in)) # 각 병렬 layer shape에 따라 input 받음
            input2[unit] = Bidirectional(LSTM(n_hidden))(input1[unit]) # biRNN -> 시계열에서 단일 value로 나감
            input2[unit] = Dense(layer_1, kernel_initializer = init, activation='relu')(input2[unit]) # fully conneted layers, relu
            input2[unit] = Dropout(dropout_rate1)(input2[unit]) # dropout
        
        added = keras.layers.Add()(input2) # 병렬구조를 여기서 모두 합침
        merge_1 = Dense(layer_1, kernel_initializer = init, activation='relu')(added) # fully conneted layers, relu
        merge_2 = Dropout(dropout_rate2)(merge_1) # dropout
        merge_2 = Dense(n_out, kernel_initializer = init, activation='sigmoid')(merge_2) # fully conneted layers, sigmoid
        merge_3 = Dense(n_out, input_dim=n_out, kernel_regularizer=regularizers.l2(l2_rate))(merge_2) # regularization
        merge_4 = Activation('softmax')(merge_3) # activation as softmax function
        
        model = keras.models.Model(inputs=input1, outputs=merge_4) # input output 선언
        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr, beta_1=0.9, beta_2=0.999), metrics=['accuracy']) # optimizer
        
        #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras  #### keras #### keras
        return model, idcode
    
    model, idcode = keras_setup()        
    initial_weightsave = RESULT_SAVE_PATH + 'model//' + 'initial_weight.h5'
    model.save_weights(initial_weightsave)
    
    if False: # 시각화 
        # 20190903, VS code로 옮긴뒤로 에러나는 중, 해결필요
        print(model.summary())
        
        from contextlib import redirect_stdout
        
        with open('modelsummary.txt', 'w') as f:
            with redirect_stdout(f):
                model.summary()
                
        from keras.utils import plot_model
        plot_model(model, to_file='model.png')
        
             
    ##
        
    print('acc_thr', acc_thr, '여기까지 학습합니다.')
    print('maxepoch', maxepoch)
    
    # training set 재설정
    trainingset = trainingset; etc = []
    forlist = list(trainingset)
    for SE in forlist:
        c1 = np.sum(indexer[:,0]==SE) == 0 # 옥으로 전혀 선택되지 않았다면 test set으로 빼지 않음
        if c1 and SE in trainingset:
            trainingset.remove(SE)
            print('removed', SE)

    mouselist = trainingset
    mouselist.sort()
    
#    if savepath == 'E:\\mscore\\syncbackup\\paindecoder\\save\\tensorData\\':
#    mouselist = list(np.sort(np.array(mouselist))[::-1]) # runlist reverse
    
    if not(len(etc) == 0):
        mouselist.append(etc[0])
    
    # 학습할 set 결정, 따로 조작하지 않을 땐 mouselist로 설정하면 됨.
    wanted = mouselist
#    wanted = np.sort(wanted)
    mannual = [] # 절대 아무것도 넣지마 

    print('mouselist', mouselist)
    print('etc', etc)
    for i in wanted:
        try:
            mannual.append(np.where(np.array(mouselist)==i)[0][0])
        except:
            print(i, 'is excluded.', 'etc group에서 확인')
            
    print('wanted', np.array(mouselist)[mannual])
            
#    np.random.seed(seed2)
#    shuffleix = list(range(len(mannual)))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
#    np.random.shuffle(shuffleix)
#    print('shuffleix', shuffleix)
#    mannual = np.array(mannual)[shuffleix]
#    print('etc ix', np.where(np.array(mouselist)== etc)[0])
#     구지 mannual을 두고 다시 indexing 하는 이유는, 인지하기 편하기 때문임. 딱히 안써도 됨
    
    # save_hyper_parameters 기록남기기
    save_hyper_parameters = []
    save_hyper_parameters.append(['settingID', settingID])
    save_hyper_parameters.append(['epochs', epochs])
    save_hyper_parameters.append(['lr', lr])
    save_hyper_parameters.append(['n_hidden', n_hidden])
    save_hyper_parameters.append(['layer_1', layer_1])
    save_hyper_parameters.append(['l2_rate', l2_rate])
    save_hyper_parameters.append(['dropout_rate1', dropout_rate1])
    save_hyper_parameters.append(['dropout_rate2', dropout_rate2])
    save_hyper_parameters.append(['acc_thr', acc_thr])
    save_hyper_parameters.append(['batch_size', batch_size])
    save_hyper_parameters.append(['seed', seed])
#    save_hyper_parameters.append(['classratio', classratio])
    save_hyper_parameters.append(['mouselist', mouselist])
    save_hyper_parameters.append(['full_sequence', full_sequence])
    
    
    
    savename4 = RESULT_SAVE_PATH + 'model/' + '00_model_save_hyper_parameters.csv'
    
    if not (os.path.isfile(savename4)):
        print(settingID, 'prameter를 저장합니다. prameter를 저장합니다. prameter를 저장합니다.')
        csvfile = open(savename4, 'w', newline='')
        csvwriter = csv.writer(csvfile)
        for row in range(len(save_hyper_parameters)):
            csvwriter.writerow(save_hyper_parameters[row])
        csvfile.close()
        
    # In[]

    bRNN = np.zeros((N,3)); bRNN[:] = np.nan

    sett = 0; ix = 0; state = 'exp' # for test
    for state in statelist:
        for ix, sett in enumerate(mannual):
            # training 구문입니다.
            exist_model = False; recent_model = False

            # training된 model이 있는지 검사
            if state == 'exp':
                final_weightsave = RESULT_SAVE_PATH + 'model/' + str(mouselist[sett]) + '_my_model_weights_final.h5'
        #        print('exp')
            elif state == 'con':
                final_weightsave = RESULT_SAVE_PATH + 'model/' + str(mouselist[sett]) + '_my_model_weights_final_control.h5'
        #        print('con')

            print('final_weightsave', final_weightsave)

            try:
                model.load_weights(final_weightsave) 
                exist_model = True
                print('exist_model', exist_model)
            except:
                exist_model = False
                print('exist_model', exist_model, 'load 안됨')

            # 없다면, 2시간 이내에 training이 시작되었는지 검사
            if not(exist_model) and trainingsw:
                if state == 'exp':
                    loadname = RESULT_SAVE_PATH + 'tmp/' + str([mouselist[sett]]) + '_log.csv'
                elif state == 'con':
                    loadname = RESULT_SAVE_PATH + 'tmp/' + str([mouselist[sett]]) + '_log_control.csv'

                try:
                    mscsv = []       
                    f = open(loadname, 'r', encoding='utf-8')
                    rdr = csv.reader(f)
                    for line in rdr:
                        mscsv.append(line)
                    f.close()    
                    mscsv = np.array(mscsv)

                    dt = datetime.now()
                    idcode = dt.year * 10**4 + dt.month * 10**(4-2) + dt.day * 10**(4-4) + dt.hour * 10**(4-6)

                    sameday = int(idcode) == int(float(mscsv[0][0]))
                    hour_diff = ((idcode - int(idcode)) - (float(mscsv[0][0]) - int(float(mscsv[0][0])))) * 100
                    if sameday:
                        print('mouse #', [mouselist[sett]], '은', hour_diff, '시간전에 학습을 시작했습니다.')
                        if hour_diff < 2.0:
                            recent_model = True
                        elif hour_diff >= 2.0:
                            recent_model = False    
                    recent_model = False # 임시로 종료   
                except:
                    recent_model = False

                # control은 추가로, exp plot이 되어있는지 확인
                if state == 'con':
                    try:
                        loadname2 = RESULT_SAVE_PATH + 'model/' + str(mouselist[sett]) + '_' + 'exp' + '_trainingSet_result.csv'
                        f = open(loadname2, 'r', encoding='utf-8')
                        f.close()
                    except:
                        print(mouselist[sett], 'exp pair 없음, control 진행을 멈춥니다.')
                        recent_model = True
                # 학습된 모델도 없고, 최근에 진행중인것도 없으니 학습 시작합니다.    
                if not(recent_model):
                    print('mouse #', [mouselist[sett]], '학습된', state, 'model 없음. 새로시작합니다.')
                    model.load_weights(initial_weightsave)
                    dt = datetime.now()
                    idcode = dt.year * 10**4 + dt.month * 10**(4-2) + dt.day * 10**(4-4) + dt.hour * 10**(4-6)
                        
                    # 나중에 idcode는 없애던지.. 해야될듯 
                    
                    df2 = [idcode]
                    csvfile = open(loadname, 'w', newline='')
                    csvwriter = csv.writer(csvfile)
                    csvwriter.writerow(df2)         
                    csvfile.close() 

                    X_training = []; [X_training.append([]) for i in range(msunit *fn)] # input은 msunit만큼 병렬구조임으로 list도 여러개 만듦
                    X_valid = []; [X_valid.append([]) for i in range(msunit *fn)]
                    Y_training_list = []
                    Y_training_control_list = []
#                    Y_training = np.array(Y); Y_training_control = np.array(Y_control)# 여기서 뺸다
                    
                    # cross validation을 위해 test set을 제거함
                    delist = np.where(indexer[:,0]==mouselist[sett])[0]
                    
#                    if mouselist[sett] in np.array(msset)[:,0]:
#                        for u in np.array(msset)[np.where(np.array(msset)[:,0] == mouselist[sett])[0][0],:][1:]:
#                            delist = np.concatenate((delist, np.where(indexer[:,0]==u)[0]), axis=0)
                    
                    for unit in range(msunit *fn): # input은 msunit 만큼 병렬구조임. for loop으로 각자 계산함
                        X_training[unit] = np.delete(np.array(X[unit]), delist, 0)
#                        X_valid[unit] = np.array(X[unit])[delist]
                
                    Y_training_list = np.delete(np.array(Y), delist, 0)
                    Y_training_control_list = np.delete(np.array(Y_control), delist, 0)
#                    Y_valid = np.array(Y)[delist]
                    
#                    valid = tuple([X_valid, Y_valid])
                    
                    # validation을 위해 test set을 따로 뺌
                    if validation_sw:
                        X_tmp = []; Y_tmp = []
                        for se in range(3):
                            init = False
                            c1 = mouselist[sett] in capsaicinGroup and se in [0]
                            c2 = mouselist[sett] in vehicleGroup and se in [0,1,2]
                            
                            if c1 or c2:
                                msclass = 0; init = True
                            
                            c3 = mouselist[sett] in capsaicinGroup and se in [1]
                            if c3: # 
                                msclass = 1; init = True
                                
                            if init:
                                binning = list(range(0,(signalss[mouselist[sett]][se].shape[0]-full_sequence), bins))
                                binNum = len(binning)
                                
                                if signalss[mouselist[sett]][se].shape[0] == full_sequence:
                                    binNum = 1
                                    binning = [0]
                                    
                                for i in range(binNum):     
                                    mannual_signal  = signalss[mouselist[sett]][se][binning[i]:binning[i]+full_sequence]
                                    mannual_signal = np.reshape(mannual_signal, (mannual_signal.shape[0], 1))
                            
                                    mannual_signal2 = behavss[mouselist[sett]][se][binning[i]:binning[i]+full_sequence]
                                    mannual_signal2 = np.reshape(mannual_signal2, (mannual_signal2.shape[0], 1))
                                    
                                    mannual_signal3 = signalss_pc[mouselist[sett]][se][binning[i]:binning[i]+full_sequence]
                                    mannual_signal3 = np.reshape(mannual_signal3, (mannual_signal3.shape[0], 1))
                                    
                                    Xtest, Ytest, _, _ = dataGeneration(SE, se, label=msclass, \
                                                   mannual_signal=mannual_signal, mannual_signal2=mannual_signal2 \
                                                   , mannual_signal3=mannual_signal3)
                                    
                                    X_tmp += Xtest; Y_tmp += Ytest
                                    
                        Y_valid = np.array(Y_tmp)                
                        if Y_valid.shape[0] != 0:      
                            Xtest = array_recover(X_tmp); 
                            Y_tmp = np.array(Y_tmp); Y_tmp = np.reshape(Y_tmp, (Y_tmp.shape[0], n_out))
                                        
                            valid = tuple([Xtest, Y_tmp])
                                    
                    print('학습시작시간을 기록합니다.', df2)        
                    print('mouse #', [mouselist[sett]])
                    print('sample distributions.. ', np.round(np.mean(Y_training_list, axis = 0), 4))
                    
                    # bias 방지를 위해 동일하게 shuffle 
                    np.random.seed(seed)
                    shuffleix = list(range(X_training[0].shape[0]))
                    np.random.shuffle(shuffleix) 
#                    print(shuffleix)
   
                    tr_y_shuffle = Y_training_list[shuffleix]
                    tr_y_shuffle_control = Y_training_control_list[shuffleix]

                    tr_x = []
                    for unit in range(msunit *fn):
                        tr_x.append(X_training[unit][shuffleix])


                    # 특정 training acc를 만족할때까지 epoch를 epochs단위로 지속합니다.
                    current_acc = -np.inf; cnt = -1
                    hist_save_loss = []
                    hist_save_acc = []
                    hist_save_val_loss = []
                    hist_save_val_acc = []
                                
                    
                    while current_acc < acc_thr: # 0.93: # 목표 최대 정확도, epoch limit
#                    for t in range(60):
#                        print('stop 조건을 표시합니다')
                        print('current_acc', current_acc, 'acc_thr', acc_thr)
                        if cnt > 70:
                            break
                        

                        if cnt > 50 and current_acc < 0.8:
                            seed += 1
                            model, idcode = keras_setup()        
                            initial_weightsave = RESULT_SAVE_PATH + 'model//' + 'initial_weight.h5'
                            model.save_weights(initial_weightsave)
                            dt = datetime.now()
                            idcode = dt.year * 10**4 + dt.month * 10**(4-2) + dt.day * 10**(4-4) + dt.hour * 10**(4-6)
                            current_acc = -np.inf; cnt = -1
                            print('seed 변경, model reset 후 처음부터 다시 학습합니다.')

                        cnt += 1; # print('cnt', cnt, 'current_acc', current_acc)

                        if state == 'exp':
                            current_weightsave = RESULT_SAVE_PATH + 'tmp/'+ str(idcode) + '_' + str(mouselist[sett]) + '_my_model_weights.h5'
                        elif state == 'con':
                            current_weightsave = RESULT_SAVE_PATH + 'tmp/'+ str(idcode) + '_' + str(mouselist[sett]) + '_my_model_weights_control.h5'

                        try:
                            if cnt != 0:
                                model.load_weights(current_weightsave)
                                print('mouse #', [mouselist[sett]], cnt, '번째 이어서 학습합니다.')
                            else:
                                print('학습 진행중인 model 없음. 새로 시작합니다')

                        except:
                            print('학습 진행중인 model 없음. 새로 시작합니다')

                        # control 전용, control_epochs 구하기
                        if state == 'con':
                            mscsv = []
                            f = open(loadname2, 'r', encoding='utf-8')
                            rdr = csv.reader(f)
                            for line in rdr:
                                mscsv.append(line)
                            f.close()    
                            mscsv = np.array(mscsv)
                            control_epochs = mscsv.shape[1]
                        
#                        # validation이 가치가없으므로 끔 
#                        validation_sw = False
                        
  
                        if validation_sw and Y_valid.shape[0] != 0 and state == 'exp':
                            #1
                            hist = model.fit(tr_x, tr_y_shuffle, batch_size = batch_size, epochs = 1) #, validation_data = valid)
                            hist_save_loss += list(np.array(hist.history['loss'])); hist_save_acc += list(np.array(hist.history['accuracy']))
#                            hist_save_val_loss += list(np.array(hist.history['val_loss']))
#                            hist_save_val_acc += list(np.array(hist.history['val_accuracy'])) 
                            
                        model.save_weights(current_weightsave)
                        
                        nonpainix = np.where(valid[1][:,0] == 1,)[0]
                        painix = np.where(valid[1][:,0] == 0,)[0]
                        
                        valid_nonpain = []
                        for y in range(msunit*fn):
                            valid_nonpain.append(valid[0][y][nonpainix])
                        predict_nonpain = model.predict(valid_nonpain)
                        
                              
                        valid_pain = []
                        for y in range(msunit*fn):
                            valid_pain.append(valid[0][y][painix])
                        predict_pain = model.predict(valid_pain)
                        
                        totalsample = nonpainix.shape[0] + painix.shape[0]
                        
                        if len(list(predict_pain)) == 0:
                            msacc = (1-np.mean(predict_nonpain[:,1]))
                            print('nonpain', np.mean(predict_nonpain[:,1]) \
                              , 'msacc', round(msacc*100,2), '%')
                        else:
                            msacc = ((1-np.mean(predict_nonpain[:,1]))*nonpainix.shape[0] + np.mean(predict_pain[:,1])*painix.shape[0])/totalsample
                            print('nonpain', np.mean(predict_nonpain[:,1]), 'pain', np.mean(predict_pain[:,1]) \
                              , 'msacc', round(msacc*100,2), '%')
                        hist_save_val_acc += [msacc]
                        
                        
                        
                        
                        # 종료조건:
                        
                        meanrange = 5
                        if len(hist_save_acc) > meanrange:
                            current_acc = hist_save_acc[-meanrange]
                        else:
                            current_acc = 0
                        
                        if state == 'con':
                            current_acc = np.inf

#                        if cnt > 50 and current_acc < 0.8:
#                            # 700 epochs 후에도 학습이 안되고 있다면 초기화
#                            print('고장남.. 초기화')
#                            cnt = np.inf
                            
#                        break # test용 while바로 종료

                    # 학습 model 최종 저장
                    #5: 마지막으로 validation 찍음
#                    if validation_sw and Y_valid.shape[0] != 0 and state == 'exp':
#                        hist = model.fit(tr_x, tr_y_shuffle, batch_size = batch_size, epochs = 5) #, validation_data = valid)
#                        hist_save_loss += list(np.array(hist.history['loss'])); hist_save_acc += list(np.array(hist.history['accuracy']))
#                        
#                        hist = model.fit(tr_x, tr_y_shuffle, batch_size = batch_size, epochs = 1, validation_data = valid)
#                        hist_save_loss += list(np.array(hist.history['loss'])); hist_save_acc += list(np.array(hist.history['accuracy']))
#                        hist_save_val_loss += list(np.array(hist.history['val_loss']))
#                        hist_save_val_acc += list(np.array(hist.history['val_accuracy']))
#                    elif (not(validation_sw) or Y_valid.shape[0] == 0) and state == 'exp': 
#                        hist = model.fit(tr_x, tr_y_shuffle, batch_size = batch_size, epochs = 5+1) #, validation_data = valid)
#                        hist_save_loss += list(np.array(hist.history['loss'])); hist_save_acc += list(np.array(hist.history['accuracy']))
                    
                    model.save_weights(final_weightsave)   
                    print('mouse #', [mouselist[sett]], 'traning 종료, final model을 저장합니다.')

                    # hist 저장      
                    plt.figure();
                    mouseNum = mouselist[sett]
                    plt.plot(hist_save_loss, label= '# ' + str(mouseNum) + ' loss')
                    plt.plot(hist_save_acc, label= '# ' + str(mouseNum) + ' acc')
                    plt.legend()
                    plt.savefig(RESULT_SAVE_PATH + 'model/' + str(mouseNum) + '_' + state + '_trainingSet_result.png')
                    plt.close()

                    savename = RESULT_SAVE_PATH + 'model/' + str(mouseNum) + '_' + state + '_trainingSet_result.csv'
                    csvfile = open(savename, 'w', newline='')
                    csvwriter = csv.writer(csvfile)
                    csvwriter.writerow(hist_save_acc)
                    csvwriter.writerow(hist_save_loss)
                    csvfile.close()

                    if validation_sw and state == 'exp':
                        plt.figure();
                        mouseNum = mouselist[sett]
                        plt.plot(hist_save_val_loss, label= '# ' + str(mouseNum) + ' loss')
                        plt.plot(hist_save_val_acc, label= '# ' + str(mouseNum) + ' acc')
                        plt.legend()
                        plt.savefig(RESULT_SAVE_PATH + 'model/' + str(mouseNum) + '_' + state + '_validationSet_result.png')
                        plt.close()

                        savename = RESULT_SAVE_PATH + 'model/' + str(mouseNum) + '_' + state + '_validationSet_result.csv'
                        csvfile = open(savename, 'w', newline='')
                        csvwriter = csv.writer(csvfile)
                        csvwriter.writerow(hist_save_val_acc)
                        csvwriter.writerow(hist_save_val_loss)
                        csvfile.close()

            ####### test 구문 입니다. ##########        
            
            # 단일 cv set에서 대해서 기본적인 test list는 cv training 에서 제외된 data가 된다.
            # 단, training에 전혀 사용하지 않는 set = etc set에 대해서는 모든 training set으로 cv training 후,
            # 모든 etc set에 대해서 test 하므로, 이 경우 test list는 모든 etc set이 된다. 
            
            testlist = []
            testlist = [mouselist[sett]]
            
#            if mouselist[sett] in np.array(msset)[:,0]:
#                for u in np.array(msset)[np.where(np.array(msset)[:,0] == mouselist[sett])[0][0],:][1:]:
#                    testlist.append(u)
 
            if not(len(etc) == 0):
                if etc[0] == mouselist[sett]:
                    print('test ssesion, etc group 입니다.') 
                    testlist = list(etc)
            
            if state == 'exp':
                final_weightsave = RESULT_SAVE_PATH + 'model/' + str(mouselist[sett]) + '_my_model_weights_final.h5'
            elif state == 'con':
                final_weightsave = RESULT_SAVE_PATH + 'model/' + str(mouselist[sett]) + '_my_model_weights_final_control.h5'

            trained_fortest = False
            print(final_weightsave)
            try:
                model.load_weights(final_weightsave)
                trained_fortest =  True
                print('trained_fortest', trained_fortest)
            except:
                trained_fortest = False
                print('trained_fortest', trained_fortest)
        
            ####### test - binning 구문 입니다. ##########, test version 2
            # model load는 cv set 시작에서 무조건 하도록 되어 있음.
            if trained_fortest and testsw2:   
                for test_mouseNum in testlist:
                    testbin = None
                    picklesavename = RESULT_SAVE_PATH + 'exp_raw/' + 'PSL_result_' + str(test_mouseNum) + '.pickle'
                    try:
                        with open(picklesavename, 'rb') as f:  # Python 3: open(..., 'rb')
                            tmp = pickle.load(f)
                            testbin = False
                            print('PSL_result_' + str(test_mouseNum) + '.pickle', '이미 존재합니다. skip')
                    except:
                        testbin = True
                        
                    testbin = True
                    if testbin:
                        PSL_result_save = []
                        [PSL_result_save.append([]) for i in range(N)]
                        for SE2 in range(N):
                            [PSL_result_save[SE2].append([]) for i in range(5)]
                        # PSL_result_save변수에 무조건 동일한 공간을 만들도록 설정함. pre allocation 개념
           
                        sessionNum = 3
                        for se in range(sessionNum):
                            
                            binning = list(range(0,(signalss[test_mouseNum][se].shape[0]-full_sequence), bins))
                            binNum = len(binning)
                            
                            if signalss[test_mouseNum][se].shape[0] == full_sequence:
                                binNum = 1
                                binning = [0]
                                                           
                            [PSL_result_save[test_mouseNum][se].append([]) for i in range(binNum)]
                            
                            X_tmp = []
                            for i in range(binNum):         
                                mssignal1 = signalss[test_mouseNum][se][binning[i]:binning[i]+full_sequence]
                                mssignal2 = behavss[test_mouseNum][se][binning[i]:binning[i]+full_sequence]
                                mssignal3 = signalss_pc[test_mouseNum][se][binning[i]:binning[i]+full_sequence]
                                
                                mannual_signal = mssignal1
                                mannual_signal = np.reshape(mannual_signal, (mannual_signal.shape[0], 1))
                                mannual_signal2 = mssignal2
                                mannual_signal2 = np.reshape(mannual_signal2, (mannual_signal2.shape[0], 1))
                                mannual_signal3 = mssignal3
                                mannual_signal3 = np.reshape(mannual_signal3, (mannual_signal3.shape[0], 1))
                                
                                
                                Xtest, _, _, _ = dataGeneration(SE, se, label=1, \
                                               mannual_signal=mannual_signal, mannual_signal2=mannual_signal2 \
                                               , mannual_signal3=mannual_signal3)
                                
                                X_tmp += Xtest
                                
                                ##
                                
                            ##
                            X_tmp = array_recover(X_tmp)
                            prediction = model.predict(X_tmp)
                            bRNN[test_mouseNum, se] = np.mean(prediction[:,1])
                            print(test_mouseNum , se , i, np.mean(prediction[:,1]))
                            PSL_result_save[test_mouseNum][se][i] = prediction
                            
                            
                        
                        with open(picklesavename, 'wb') as f:  # Python 3: open(..., 'wb')
                            pickle.dump(PSL_result_save, f, pickle.HIGHEST_PROTOCOL)
                            print(picklesavename, '저장되었습니다.')
    bRNN_save.append(bRNN)
bRNN_mean = np.mean(bRNN_save, axis=0)
picklesavename = savepath + 'msGroup_ksh_bRNN.pickle'
with open(picklesavename, 'wb') as f:  # Python 3: open(..., 'wb')
    pickle.dump(bRNN_mean, f, pickle.HIGHEST_PROTOCOL)
    print(picklesavename, '저장되었습니다.')

# In[]
    
stdlist = bRNN_mean / np.std(bRNN_save, axis=0)
print('std ratio max', np.max(stdlist), 'std ratio mean', np.mean(stdlist))


















#
